{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ceffd36-d957-4602-9af7-58581aed7dc1",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3b8a3-bd86-41cb-a4a4-94cfc2411b5c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "Min-Max scaling, also known as feature scaling or normalization, is a data preprocessing technique used to transform numerical features in a dataset to a specific range. The purpose of Min-Max scaling is to bring all the feature values within a common range, typically between 0 and 1. This can be helpful in various machine learning algorithms and models, as it ensures that no feature dominates the others solely due to its larger magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58939884-63e5-4b03-a6e7-22aabca177f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4adb5bb9-e024-40a2-b9f4-c1b883fb6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"taxis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a0a15c-59b7-4757-b7a1-d9c120698fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "      <th>passengers</th>\n",
       "      <th>distance</th>\n",
       "      <th>fare</th>\n",
       "      <th>tip</th>\n",
       "      <th>tolls</th>\n",
       "      <th>total</th>\n",
       "      <th>color</th>\n",
       "      <th>payment</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>pickup_borough</th>\n",
       "      <th>dropoff_borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-23 20:21:09</td>\n",
       "      <td>2019-03-23 20:27:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.95</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Lenox Hill West</td>\n",
       "      <td>UN/Turtle Bay South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-04 16:11:55</td>\n",
       "      <td>2019-03-04 16:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.30</td>\n",
       "      <td>yellow</td>\n",
       "      <td>cash</td>\n",
       "      <td>Upper West Side South</td>\n",
       "      <td>Upper West Side South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-27 17:53:01</td>\n",
       "      <td>2019-03-27 18:00:25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.16</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>West Village</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-10 01:23:59</td>\n",
       "      <td>2019-03-10 01:49:51</td>\n",
       "      <td>1</td>\n",
       "      <td>7.70</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.95</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Hudson Sq</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-30 13:27:42</td>\n",
       "      <td>2019-03-30 13:37:14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.16</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.40</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Midtown East</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pickup             dropoff  passengers  distance  fare   tip  \\\n",
       "0 2019-03-23 20:21:09 2019-03-23 20:27:24           1      1.60   7.0  2.15   \n",
       "1 2019-03-04 16:11:55 2019-03-04 16:19:00           1      0.79   5.0  0.00   \n",
       "2 2019-03-27 17:53:01 2019-03-27 18:00:25           1      1.37   7.5  2.36   \n",
       "3 2019-03-10 01:23:59 2019-03-10 01:49:51           1      7.70  27.0  6.15   \n",
       "4 2019-03-30 13:27:42 2019-03-30 13:37:14           3      2.16   9.0  1.10   \n",
       "\n",
       "   tolls  total   color      payment            pickup_zone  \\\n",
       "0    0.0  12.95  yellow  credit card        Lenox Hill West   \n",
       "1    0.0   9.30  yellow         cash  Upper West Side South   \n",
       "2    0.0  14.16  yellow  credit card          Alphabet City   \n",
       "3    0.0  36.95  yellow  credit card              Hudson Sq   \n",
       "4    0.0  13.40  yellow  credit card           Midtown East   \n",
       "\n",
       "            dropoff_zone pickup_borough dropoff_borough  \n",
       "0    UN/Turtle Bay South      Manhattan       Manhattan  \n",
       "1  Upper West Side South      Manhattan       Manhattan  \n",
       "2           West Village      Manhattan       Manhattan  \n",
       "3         Yorkville West      Manhattan       Manhattan  \n",
       "4         Yorkville West      Manhattan       Manhattan  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2b0215-b8a1-45c7-8bab-d65e7464d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b0c8f9-1140-411b-9845-173ee07963f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faedba43-9506-4b65-b01c-a2689be52fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21aa456f-c88a-4af6-84be-b316291dbd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup', 'dropoff', 'passengers', 'distance', 'fare', 'tip', 'tolls',\n",
       "       'total', 'color', 'payment', 'pickup_zone', 'dropoff_zone',\n",
       "       'pickup_borough', 'dropoff_borough'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2fe86d8-29f5-422a-afe9-375574b6fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = pd.DataFrame(min_max.fit_transform(df[['distance', 'fare', 'tip']]),columns = ['distance', 'fare', 'tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea2fe121-8eb0-4cc2-b434-7e6cc4171d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>fare</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.064759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037330</td>\n",
       "      <td>0.043624</td>\n",
       "      <td>0.071084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209809</td>\n",
       "      <td>0.174497</td>\n",
       "      <td>0.185241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058856</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>0.033133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>0.020436</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.031928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>0.510627</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.112807</td>\n",
       "      <td>0.100671</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.104905</td>\n",
       "      <td>0.093960</td>\n",
       "      <td>0.101205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6433 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance      fare       tip\n",
       "0     0.043597  0.040268  0.064759\n",
       "1     0.021526  0.026846  0.000000\n",
       "2     0.037330  0.043624  0.071084\n",
       "3     0.209809  0.174497  0.185241\n",
       "4     0.058856  0.053691  0.033133\n",
       "...        ...       ...       ...\n",
       "6428  0.020436  0.023490  0.031928\n",
       "6429  0.510627  0.382550  0.000000\n",
       "6430  0.112807  0.100671  0.000000\n",
       "6431  0.030518  0.033557  0.000000\n",
       "6432  0.104905  0.093960  0.101205\n",
       "\n",
       "[6433 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387431f-23e8-4520-9fe3-53e7c334a0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b4f5fb-fb01-409f-ac58-7a760cba355a",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce5e12-795d-478c-b6c2-758304bfcb99",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The Unit Vector technique, also known as vector normalization, is another method of feature scaling used in data preprocessing. Unlike Min-Max scaling, which scales features to a specific range (usually [0, 1]), the Unit Vector technique scales the features such that each data point (or feature vector) has a Euclidean norm (magnitude) of 1. In other words, it transforms the features to lie on the surface of a unit hypersphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d9d7968-de70-4dca-b138-615221f9e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE MIN MAX SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3156bd1-24db-4931-b868-478df642f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a248ba0-5bfb-4657-af50-6402da31a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c335019a-d950-4d9d-93e4-cddaaac1eece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup', 'dropoff', 'passengers', 'distance', 'fare', 'tip', 'tolls',\n",
       "       'total', 'color', 'payment', 'pickup_zone', 'dropoff_zone',\n",
       "       'pickup_borough', 'dropoff_borough'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "063babaf-745f-4d3e-b0a6-51eeed5d5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = pd.DataFrame(min_max.fit_transform(df[['distance', 'fare', 'tip']]),columns = ['distance', 'fare', 'tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c452e20-3da5-4817-a357-bdfa47ba7f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>fare</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.064759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037330</td>\n",
       "      <td>0.043624</td>\n",
       "      <td>0.071084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209809</td>\n",
       "      <td>0.174497</td>\n",
       "      <td>0.185241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058856</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>0.033133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>0.020436</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.031928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>0.510627</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.112807</td>\n",
       "      <td>0.100671</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.104905</td>\n",
       "      <td>0.093960</td>\n",
       "      <td>0.101205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6433 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance      fare       tip\n",
       "0     0.043597  0.040268  0.064759\n",
       "1     0.021526  0.026846  0.000000\n",
       "2     0.037330  0.043624  0.071084\n",
       "3     0.209809  0.174497  0.185241\n",
       "4     0.058856  0.053691  0.033133\n",
       "...        ...       ...       ...\n",
       "6428  0.020436  0.023490  0.031928\n",
       "6429  0.510627  0.382550  0.000000\n",
       "6430  0.112807  0.100671  0.000000\n",
       "6431  0.030518  0.033557  0.000000\n",
       "6432  0.104905  0.093960  0.101205\n",
       "\n",
       "[6433 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7614709d-838b-4faa-ae19-0296609d0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE OF UNIT VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2055f473-6e33-4d8d-a83c-80fb02f7cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3ca1dc7-3474-4eb0-9ae5-ec02e5a8bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_vector = pd.DataFrame(normalize(df[['distance', 'fare', 'tip']]),columns = ['distance', 'fare', 'tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daf829c2-1281-4a0a-99f9-e0d99e3dcfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>fare</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213461</td>\n",
       "      <td>0.933894</td>\n",
       "      <td>0.286839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.987747</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>0.295702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.267899</td>\n",
       "      <td>0.939386</td>\n",
       "      <td>0.213971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231742</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.118017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>0.160133</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.226322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.951563</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.968117</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.183497</td>\n",
       "      <td>0.983020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.242956</td>\n",
       "      <td>0.946580</td>\n",
       "      <td>0.212034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6433 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance      fare       tip\n",
       "0     0.213461  0.933894  0.286839\n",
       "1     0.156064  0.987747  0.000000\n",
       "2     0.171657  0.939731  0.295702\n",
       "3     0.267899  0.939386  0.213971\n",
       "4     0.231742  0.965592  0.118017\n",
       "...        ...       ...       ...\n",
       "6428  0.160133  0.960800  0.226322\n",
       "6429  0.307453  0.951563  0.000000\n",
       "6430  0.250500  0.968117  0.000000\n",
       "6431  0.183497  0.983020  0.000000\n",
       "6432  0.242956  0.946580  0.212034\n",
       "\n",
       "[6433 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05200a8e-d59e-422f-a4e4-9b8be013a81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4761e2d7-4072-4b1b-b586-95643e4cfc5f",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c53dd-718c-4a9b-8afd-51bc23327e06",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "PCA, or Principal Component Analysis, is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional space while retaining as much of the original variability as possible. It achieves this by identifying the principal components, which are orthogonal (uncorrelated) linear combinations of the original features. These principal components capture the directions of maximum variance in the data, allowing for a more compact representation of the data while minimizing information loss.\n",
    "\n",
    "The steps of PCA are as follows:\n",
    "\n",
    "Standardize the data: Ensure that the features have zero mean and unit variance.\n",
    "Calculate the covariance matrix: Compute the covariance matrix of the standardized data.\n",
    "Calculate the eigenvalues and eigenvectors: Find the eigenvalues and corresponding eigenvectors of the covariance matrix.\n",
    "Sort eigenvalues: Sort the eigenvalues in decreasing order to identify the most significant principal components.\n",
    "Select principal components: Choose the top 'k' eigenvectors to form the new lower-dimensional subspace (where 'k' is the desired number of dimensions).\n",
    "Transform data: Project the original data onto the selected principal components to obtain the lower-dimensional representation.\n",
    "Example:\n",
    "Let's consider a dataset of two features, 'Height' (in inches) and 'Weight' (in pounds), for a group of individuals. We'll use PCA to reduce the dimensionality of this dataset from two to one dimension.\n",
    "\n",
    "Original dataset (in inches and pounds):\n",
    "| Height | Weight |\n",
    "|--------|--------|\n",
    "| 65     | 150    |\n",
    "| 70     | 160    |\n",
    "| 72     | 165    |\n",
    "| 61     | 120    |\n",
    "| 63     | 130    |\n",
    "Standardize the data:\n",
    "Calculate the mean and standard deviation for each feature and standardize the data.\n",
    "\n",
    "Calculate the covariance matrix:\n",
    "Compute the covariance matrix for the standardized data.\n",
    "\n",
    "Calculate eigenvalues and eigenvectors:\n",
    "Find the eigenvalues and eigenvectors of the covariance matrix.\n",
    "\n",
    "Sort eigenvalues:\n",
    "Sort the eigenvalues in decreasing order.\n",
    "\n",
    "Select principal components:\n",
    "Let's say we want to reduce the dimensionality to one component. Select the eigenvector corresponding to the largest eigenvalue.\n",
    "\n",
    "Transform data:\n",
    "Project the original data onto the selected principal component.\n",
    "\n",
    "The transformed dataset (one-dimensional representation):\n",
    "| Transformed Data |\n",
    "|------------------|\n",
    "| 0.672            |\n",
    "| 1.524            |\n",
    "| 1.930            |\n",
    "| -1.824           |\n",
    "| -0.301           |\n",
    "In this example, we've successfully reduced the dataset from two dimensions (Height and Weight) to one dimension (Transformed Data) using PCA. The transformed data captures the most significant variability in the original data, allowing us to represent the data in a lower-dimensional space while preserving important patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a8a4d-8af8-441b-8b3f-ac16125f48fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e66ec34-f4f9-4b06-86c9-a61eec3718ce",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999fd9a8-f639-4a64-b100-19f3226ba3d7",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "PCA (Principal Component Analysis) is a technique that can be used for feature extraction, particularly in the context of dimensionality reduction. Feature extraction involves transforming the original features of a dataset into a new set of features that capture the most relevant information while reducing the dimensionality. PCA achieves feature extraction by identifying the principal components, which are new features that are linear combinations of the original features. These principal components represent the directions of maximum variance in the data and can be used as a reduced set of features.\n",
    "\n",
    "The relationship between PCA and feature extraction can be summarized as follows:\n",
    "\n",
    "PCA is a specific method of feature extraction that aims to capture the most important patterns and variability in the data by creating new features (principal components) that are linear combinations of the original features.\n",
    "Feature extraction, in general, refers to any technique that transforms the original features into a smaller set of features while retaining relevant information. PCA is one such technique for feature extraction.\n",
    "Example:\n",
    "Let's consider an image dataset consisting of grayscale images of handwritten digits (0 to 9). Each image is represented as a matrix of pixel values. We'll use PCA as a feature extraction technique to reduce the dimensionality of the images while preserving important information.\n",
    "\n",
    "Original dataset:\n",
    "\n",
    "Each image is represented as a matrix of pixel values (e.g., 28x28 pixels for a 28x28 image).\n",
    "Steps to apply PCA for feature extraction:\n",
    "\n",
    "Flatten images: Convert each 28x28 image matrix into a vector of pixel values (e.g., a 784-dimensional vector).\n",
    "\n",
    "Standardize the data: Ensure that the pixel values have zero mean and unit variance.\n",
    "\n",
    "Calculate covariance matrix: Compute the covariance matrix of the standardized data.\n",
    "\n",
    "Calculate eigenvalues and eigenvectors: Find the eigenvalues and corresponding eigenvectors of the covariance matrix.\n",
    "\n",
    "Sort eigenvalues: Sort the eigenvalues in decreasing order.\n",
    "\n",
    "Select principal components: Choose the top 'k' eigenvectors to form the new lower-dimensional subspace (where 'k' is the desired number of dimensions).\n",
    "\n",
    "Transform data: Project the original flattened images onto the selected principal components to obtain the lower-dimensional representation.\n",
    "\n",
    "By performing PCA on the flattened and standardized images, we create a reduced set of features (principal components) that capture the most significant patterns in the images. These principal components can be used as features for further analysis or classification tasks. The dimensionality reduction achieved through PCA can help reduce computational complexity, noise, and improve model performance by focusing on the most relevant information.\n",
    "\n",
    "In this example, PCA acts as a feature extraction technique by converting high-dimensional image data into a lower-dimensional representation while retaining essential patterns and information.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a79e4-6b5a-402a-8ff8-b7166f1bbdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79ecd270-1fdf-4fd1-b4a1-d5ebe0ea3b94",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731b694-f788-47c0-a012-580591709180",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "In the context of building a recommendation system for a food delivery service, Min-Max scaling can be used to preprocess the features such as price, rating, and delivery time. Min-Max scaling will transform these features into a common range (typically [0, 1]) to ensure that they have a consistent scale and to prevent any feature from dominating the others due to differences in magnitude.\n",
    "\n",
    "Here's how you would use Min-Max scaling to preprocess the data:\n",
    "\n",
    "Understand the Data: Begin by examining the dataset and understanding the range of values for each feature (price, rating, delivery time). This will help you decide whether Min-Max scaling is appropriate and necessary.\n",
    "\n",
    "Calculate Min and Max Values: Compute the minimum (\n",
    "min\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "min(x)) and maximum (\n",
    "max\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "max(x)) values for each feature (price, rating, delivery time) in the dataset.\n",
    "\n",
    "Apply Min-Max Scaling Formula: For each feature 'x', apply the Min-Max scaling formula to scale the values to the [0, 1] range:\n",
    "\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "−\n",
    "min\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "max\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "−\n",
    "min\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "x \n",
    "scaled\n",
    "​\n",
    " = \n",
    "max(x)−min(x)\n",
    "x−min(x)\n",
    "​\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "x \n",
    "scaled\n",
    "​\n",
    "  is the scaled value of the feature 'x'.\n",
    "�\n",
    "x is the original value of the feature 'x'.\n",
    "min\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "min(x) is the minimum value of feature 'x' in the dataset.\n",
    "max\n",
    "⁡\n",
    "(\n",
    "�\n",
    ")\n",
    "max(x) is the maximum value of feature 'x' in the dataset.\n",
    "Replace Original Values: Replace the original values of each feature with their scaled counterparts.\n",
    "\n",
    "Use Scaled Data for Recommendation: Once the data has been Min-Max scaled, you can use these scaled values as input features for building your recommendation system. The scaled features will ensure that no single feature dominates the recommendation process due to differences in scale.\n",
    "\n",
    "Example:\n",
    "Let's consider a simplified subset of the food delivery dataset:\n",
    "| Item       | Price ($)| Rating (0-5)| Delivery Time (min) |\n",
    "|------------|----------|-------------|---------------------|\n",
    "| Pizza      | 12       | 4.5         | 30                  |\n",
    "| Burger     | 8        | 3.8         | 25                  |\n",
    "| Salad      | 6        | 4.0         | 20                  |\n",
    "Calculate the minimum and maximum values for each feature:\n",
    "\n",
    "min\n",
    "⁡\n",
    "(\n",
    "Price\n",
    ")\n",
    "=\n",
    "6\n",
    "min(Price)=6, \n",
    "max\n",
    "⁡\n",
    "(\n",
    "Price\n",
    ")\n",
    "=\n",
    "12\n",
    "max(Price)=12\n",
    "min\n",
    "⁡\n",
    "(\n",
    "Rating\n",
    ")\n",
    "=\n",
    "3.8\n",
    "min(Rating)=3.8, \n",
    "max\n",
    "⁡\n",
    "(\n",
    "Rating\n",
    ")\n",
    "=\n",
    "4.5\n",
    "max(Rating)=4.5\n",
    "min\n",
    "⁡\n",
    "(\n",
    "Delivery Time\n",
    ")\n",
    "=\n",
    "20\n",
    "min(Delivery Time)=20, \n",
    "max\n",
    "⁡\n",
    "(\n",
    "Delivery Time\n",
    ")\n",
    "=\n",
    "30\n",
    "max(Delivery Time)=30\n",
    "Apply Min-Max scaling to each feature:\n",
    "\n",
    "For Pizza:\n",
    "Price\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "12\n",
    "−\n",
    "6\n",
    "12\n",
    "−\n",
    "6\n",
    "=\n",
    "1.0\n",
    "Price \n",
    "scaled\n",
    "​\n",
    " = \n",
    "12−6\n",
    "12−6\n",
    "​\n",
    " =1.0\n",
    "Rating\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "4.5\n",
    "−\n",
    "3.8\n",
    "4.5\n",
    "−\n",
    "3.8\n",
    "=\n",
    "1.0\n",
    "Rating \n",
    "scaled\n",
    "​\n",
    " = \n",
    "4.5−3.8\n",
    "4.5−3.8\n",
    "​\n",
    " =1.0\n",
    "Delivery Time\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "30\n",
    "−\n",
    "20\n",
    "30\n",
    "−\n",
    "20\n",
    "=\n",
    "1.0\n",
    "Delivery Time \n",
    "scaled\n",
    "​\n",
    " = \n",
    "30−20\n",
    "30−20\n",
    "​\n",
    " =1.0\n",
    "\n",
    "For Burger:\n",
    "Price\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "8\n",
    "−\n",
    "6\n",
    "12\n",
    "−\n",
    "6\n",
    "=\n",
    "0.333\n",
    "Price \n",
    "scaled\n",
    "​\n",
    " = \n",
    "12−6\n",
    "8−6\n",
    "​\n",
    " =0.333\n",
    "Rating\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "3.8\n",
    "−\n",
    "3.8\n",
    "4.5\n",
    "−\n",
    "3.8\n",
    "=\n",
    "0.0\n",
    "Rating \n",
    "scaled\n",
    "​\n",
    " = \n",
    "4.5−3.8\n",
    "3.8−3.8\n",
    "​\n",
    " =0.0\n",
    "Delivery Time\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "25\n",
    "−\n",
    "20\n",
    "30\n",
    "−\n",
    "20\n",
    "=\n",
    "0.5\n",
    "Delivery Time \n",
    "scaled\n",
    "​\n",
    " = \n",
    "30−20\n",
    "25−20\n",
    "​\n",
    " =0.5\n",
    "\n",
    "For Salad:\n",
    "Price\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "6\n",
    "−\n",
    "6\n",
    "12\n",
    "−\n",
    "6\n",
    "=\n",
    "0.0\n",
    "Price \n",
    "scaled\n",
    "​\n",
    " = \n",
    "12−6\n",
    "6−6\n",
    "​\n",
    " =0.0\n",
    "Rating\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "4.0\n",
    "−\n",
    "3.8\n",
    "4.5\n",
    "−\n",
    "3.8\n",
    "=\n",
    "0.333\n",
    "Rating \n",
    "scaled\n",
    "​\n",
    " = \n",
    "4.5−3.8\n",
    "4.0−3.8\n",
    "​\n",
    " =0.333\n",
    "Delivery Time\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "20\n",
    "−\n",
    "20\n",
    "30\n",
    "−\n",
    "20\n",
    "=\n",
    "0.0\n",
    "Delivery Time \n",
    "scaled\n",
    "​\n",
    " = \n",
    "30−20\n",
    "20−20\n",
    "​\n",
    " =0.0\n",
    "\n",
    "After Min-Max scaling, the scaled values for each feature are in the [0, 1] range, ensuring that all the features have a consistent scale. You can now use these scaled features to build your recommendation system for the food delivery service.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d9602-b90b-403d-94b6-716347846844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb363304-2864-4dd3-980c-17db3274ce81",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee6b58-25f2-4bc8-8e2f-ed7e745db47c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "When working on a project to predict stock prices using a dataset with numerous features, such as company financial data and market trends, PCA (Principal Component Analysis) can be a valuable technique for reducing the dimensionality of the dataset. Dimensionality reduction through PCA can help simplify the dataset, remove noise, and focus on the most significant patterns, which can improve the performance of your predictive model and reduce overfitting.\n",
    "\n",
    "Here's how you would use PCA to reduce the dimensionality of the dataset for predicting stock prices:\n",
    "\n",
    "Understand the Data: Begin by thoroughly understanding the dataset, including the nature of the features, their relationships, and their relevance to predicting stock prices. Identify features that are highly correlated or redundant, as these are good candidates for dimensionality reduction.\n",
    "\n",
    "Data Preprocessing: Preprocess the data by handling missing values, outliers, and scaling the features (e.g., using standardization) to ensure that all features are on a comparable scale.\n",
    "\n",
    "Calculate Covariance Matrix: Compute the covariance matrix of the standardized features. The covariance matrix provides insights into the relationships and interactions among the features.\n",
    "\n",
    "Calculate Eigenvalues and Eigenvectors: Calculate the eigenvalues and corresponding eigenvectors of the covariance matrix. The eigenvectors represent the directions of maximum variance in the dataset.\n",
    "\n",
    "Sort Eigenvalues: Sort the eigenvalues in decreasing order. This step helps you identify the principal components (eigenvectors) that capture the most significant variability in the data.\n",
    "\n",
    "Select Principal Components: Decide on the number of principal components (eigenvectors) you want to retain. You can use techniques such as explained variance or cumulative explained variance to determine the appropriate number of components.\n",
    "\n",
    "Project Data onto Principal Components: Project the original standardized data onto the selected principal components. This involves multiplying the standardized data matrix by the matrix of selected principal components.\n",
    "\n",
    "Obtain Transformed Data: The projected data onto the principal components is your reduced-dimensional dataset. Each row corresponds to an observation, and the columns represent the reduced features (principal components).\n",
    "\n",
    "Modeling: Use the reduced-dimensional dataset as input to your predictive model. Train and evaluate your model as usual.\n",
    "\n",
    "Example:\n",
    "Suppose your stock price prediction dataset contains financial metrics such as revenue, profit, debt, and market trends such as trading volume and market sentiment for multiple companies over a certain period.\n",
    "\n",
    "Understand the Data: Review the financial metrics and market trends to identify correlations and patterns.\n",
    "\n",
    "Data Preprocessing: Handle missing values, outliers, and standardize the features.\n",
    "\n",
    "Calculate Covariance Matrix: Compute the covariance matrix of the standardized features.\n",
    "\n",
    "Calculate Eigenvalues and Eigenvectors: Find the eigenvalues and eigenvectors of the covariance matrix.\n",
    "\n",
    "Sort Eigenvalues: Sort eigenvalues in decreasing order.\n",
    "\n",
    "Select Principal Components: Determine the number of principal components to retain based on explained variance.\n",
    "\n",
    "Project Data onto Principal Components: Multiply the standardized data matrix by the matrix of selected principal components.\n",
    "\n",
    "Obtain Transformed Data: The transformed data is your reduced-dimensional dataset.\n",
    "\n",
    "Modeling: Train and evaluate your predictive model using the reduced-dimensional dataset.\n",
    "\n",
    "By using PCA, you can effectively reduce the dimensionality of your stock price prediction dataset while preserving the most relevant information. This can lead to improved model performance, faster training times, and a better understanding of the underlying patterns influencing stock prices.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057d22f-d06f-43cd-8a6d-019e46987216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743a450-c22e-43f5-a47a-5b3ca9c36381",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b244b-8e9d-4300-bf16-b4305f53b465",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "To perform Min-Max scaling and transform the values in the dataset [1, 5, 10, 15, 20] to a range of -1 to 1, you can follow these steps:\n",
    "\n",
    "Calculate the minimum and maximum values in the original dataset.\n",
    "\n",
    "min\n",
    "⁡\n",
    "(\n",
    "Dataset\n",
    ")\n",
    "=\n",
    "1\n",
    "min(Dataset)=1\n",
    "max\n",
    "⁡\n",
    "(\n",
    "Dataset\n",
    ")\n",
    "=\n",
    "20\n",
    "max(Dataset)=20\n",
    "\n",
    "Apply the Min-Max scaling formula to each value in the dataset using the desired range \n",
    "[\n",
    "−\n",
    "1\n",
    ",\n",
    "1\n",
    "]\n",
    "[−1,1]:\n",
    "\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "−\n",
    "1\n",
    "+\n",
    "2\n",
    "⋅\n",
    "(\n",
    "�\n",
    "−\n",
    "min\n",
    "⁡\n",
    "(\n",
    "Dataset\n",
    ")\n",
    ")\n",
    "max\n",
    "⁡\n",
    "(\n",
    "Dataset\n",
    ")\n",
    "−\n",
    "min\n",
    "⁡\n",
    "(\n",
    "Dataset\n",
    ")\n",
    "x \n",
    "scaled\n",
    "​\n",
    " =−1+ \n",
    "max(Dataset)−min(Dataset)\n",
    "2⋅(x−min(Dataset))\n",
    "​\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "x \n",
    "scaled\n",
    "​\n",
    "  is the scaled value of the data point 'x'.\n",
    "�\n",
    "x is the original value of the data point 'x'.\n",
    "min\n",
    "⁡\n",
    "(\n",
    "Dataset\n",
    ")\n",
    "min(Dataset) is the minimum value in the dataset.\n",
    "max\n",
    "⁡\n",
    "(\n",
    "Dataset\n",
    ")\n",
    "max(Dataset) is the maximum value in the dataset.\n",
    "Calculate the scaled values for each data point using the formula.\n",
    "\n",
    "Let's perform the calculations:\n",
    "\n",
    "For \n",
    "�\n",
    "=\n",
    "1\n",
    "x=1:\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "−\n",
    "1\n",
    "+\n",
    "2\n",
    "⋅\n",
    "(\n",
    "1\n",
    "−\n",
    "1\n",
    ")\n",
    "20\n",
    "−\n",
    "1\n",
    "=\n",
    "−\n",
    "1\n",
    "x \n",
    "scaled\n",
    "​\n",
    " =−1+ \n",
    "20−1\n",
    "2⋅(1−1)\n",
    "​\n",
    " =−1\n",
    "\n",
    "For \n",
    "�\n",
    "=\n",
    "5\n",
    "x=5:\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "−\n",
    "1\n",
    "+\n",
    "2\n",
    "⋅\n",
    "(\n",
    "5\n",
    "−\n",
    "1\n",
    ")\n",
    "20\n",
    "−\n",
    "1\n",
    "≈\n",
    "−\n",
    "0.6\n",
    "x \n",
    "scaled\n",
    "​\n",
    " =−1+ \n",
    "20−1\n",
    "2⋅(5−1)\n",
    "​\n",
    " ≈−0.6\n",
    "\n",
    "For \n",
    "�\n",
    "=\n",
    "10\n",
    "x=10:\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "−\n",
    "1\n",
    "+\n",
    "2\n",
    "⋅\n",
    "(\n",
    "10\n",
    "−\n",
    "1\n",
    ")\n",
    "20\n",
    "−\n",
    "1\n",
    "≈\n",
    "−\n",
    "0.2\n",
    "x \n",
    "scaled\n",
    "​\n",
    " =−1+ \n",
    "20−1\n",
    "2⋅(10−1)\n",
    "​\n",
    " ≈−0.2\n",
    "\n",
    "For \n",
    "�\n",
    "=\n",
    "15\n",
    "x=15:\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "−\n",
    "1\n",
    "+\n",
    "2\n",
    "⋅\n",
    "(\n",
    "15\n",
    "−\n",
    "1\n",
    ")\n",
    "20\n",
    "−\n",
    "1\n",
    "≈\n",
    "0.2\n",
    "x \n",
    "scaled\n",
    "​\n",
    " =−1+ \n",
    "20−1\n",
    "2⋅(15−1)\n",
    "​\n",
    " ≈0.2\n",
    "\n",
    "For \n",
    "�\n",
    "=\n",
    "20\n",
    "x=20:\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "−\n",
    "1\n",
    "+\n",
    "2\n",
    "⋅\n",
    "(\n",
    "20\n",
    "−\n",
    "1\n",
    ")\n",
    "20\n",
    "−\n",
    "1\n",
    "=\n",
    "1\n",
    "x \n",
    "scaled\n",
    "​\n",
    " =−1+ \n",
    "20−1\n",
    "2⋅(20−1)\n",
    "​\n",
    " =1\n",
    "\n",
    "After performing Min-Max scaling, the dataset [1, 5, 10, 15, 20] has been transformed to the range of \n",
    "[\n",
    "−\n",
    "1\n",
    ",\n",
    "1\n",
    "]\n",
    "[−1,1]:\n",
    "\n",
    "Scaled dataset: [-1, -0.6, -0.2, 0.2, 1]\n",
    "\n",
    "Now, all the values in the scaled dataset are within the desired range of -1 to 1.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efcfd10-b9ae-4891-901d-0c94b7476b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe416fcc-b3ad-4927-816d-12b629633a88",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560e123-3945-4680-be7a-65ff1ae725ca",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "The decision of how many principal components to retain in a PCA-based feature extraction depends on several factors, including the variance explained by each component and the trade-off between dimensionality reduction and information loss. Let's go through the steps to determine how many principal components to retain for the given dataset of features: [height, weight, age, gender, blood pressure].\n",
    "\n",
    "Standardize the Data: Start by standardizing the dataset to have zero mean and unit variance. This is crucial for PCA to work effectively, as it is sensitive to the scale of the features.\n",
    "\n",
    "Calculate Covariance Matrix: Compute the covariance matrix of the standardized data.\n",
    "\n",
    "Calculate Eigenvalues and Eigenvectors: Find the eigenvalues and eigenvectors of the covariance matrix.\n",
    "\n",
    "Sort Eigenvalues: Sort the eigenvalues in decreasing order. The eigenvalues represent the amount of variance explained by each principal component.\n",
    "\n",
    "Explained Variance Ratio: Calculate the explained variance ratio for each principal component by dividing each eigenvalue by the sum of all eigenvalues. This gives you an idea of how much information each component captures.\n",
    "\n",
    "Cumulative Explained Variance: Calculate the cumulative explained variance by summing up the explained variance ratios. This helps you understand how much total variance is retained as you increase the number of principal components.\n",
    "\n",
    "Choose the Number of Principal Components: Decide on the number of principal components to retain based on a threshold of cumulative explained variance. A common threshold is to retain enough components to capture a significant portion (e.g., 95% or 99%) of the total variance.\n",
    "\n",
    "Since the dataset includes features related to height, weight, age, gender, and blood pressure, the number of principal components to retain will depend on the data and the desired trade-off between dimensionality reduction and information retention.\n",
    "\n",
    "For this specific dataset, you could perform the following steps:\n",
    "\n",
    "Standardize the data.\n",
    "\n",
    "Calculate the covariance matrix.\n",
    "\n",
    "Calculate eigenvalues and eigenvectors.\n",
    "\n",
    "Sort eigenvalues.\n",
    "\n",
    "Calculate explained variance ratios.\n",
    "\n",
    "Calculate cumulative explained variance.\n",
    "\n",
    "Choose a threshold for cumulative explained variance (e.g., 95% or 99%).\n",
    "\n",
    "Determine the number of principal components to retain based on the chosen threshold.\n",
    "\n",
    "The exact number of principal components to retain will vary based on the dataset and the desired level of information retention. A common approach is to plot the cumulative explained variance and visually identify the \"elbow point\" where adding more components provides diminishing returns in terms of explained variance.\n",
    "\n",
    "Remember that the goal is to strike a balance between reducing dimensionality while retaining a sufficient amount of information to capture the underlying patterns and relationships in the data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734fab6-0196-487f-9e82-455a6ffa325a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
